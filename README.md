# CLIP: Zero-Shot Image Classification 

## Dataset:
- CIFAR10
- CIFAR100

## Model
- CLIP-ViT B/32: ViT base, input 224x224 image -> 32x32 patches

## Results 
| Methods               | CIFAR-10 | CIFAR-100 |
|-----------------------|----------|-----------|
| CLIP (org repo)       | 80.0     | 47.7      |
| CLIP (HuggingFace)    | 88.8     | 61.7      |
| CLIP (paper)          | 91.3     | 65.1      |


